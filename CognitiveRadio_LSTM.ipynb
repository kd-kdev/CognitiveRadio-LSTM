{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMoV5/7b9P+gueT6CH4lT1p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kd-kdev/CognitiveRadio-LSTM/blob/main/CognitiveRadio_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Cognitive Radio - Channel occupancy prediction using LSTM\n"
      ],
      "metadata": {
        "id": "szOWLo_3FYsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[PyTorch Cognitive Radio - Channel occupancy prediction using LSTM](#scrollTo=szOWLo_3FYsy)\n",
        "\n",
        ">>[1. Import libraries & setup](#scrollTo=R-uOLgZWcB4I)\n",
        "\n",
        ">>[2. Hyperparameters](#scrollTo=8-eDK_jJLcMN)\n",
        "\n",
        ">>[3. Plotting functions](#scrollTo=T-6tgFbULffj)\n",
        "\n",
        ">>[4. Simulate channel data](#scrollTo=gVkPvKYpLuhe)\n",
        "\n",
        ">>[5. Sequence creation & DataLoader](#scrollTo=7-D_fGKNL6Jz)\n",
        "\n",
        ">>[6. LSTM model definition](#scrollTo=NXTUz7rOMFLL)\n",
        "\n",
        ">>[7. Training loop](#scrollTo=RHSHqKGMMUZw)\n",
        "\n",
        ">>[8. Evaluate model on new dataset](#scrollTo=0AvRdlELMbBy)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "gYBPhmELZqmn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.&nbsp;Import libraries & setup\n",
        "Imports all related libraries & installs packages (includes optional visualization libs), may require re-run after runtime restart."
      ],
      "metadata": {
        "id": "R-uOLgZWcB4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "def ensure(pkg, pip_name=None):\n",
        "    pip_name = pip_name or pkg\n",
        "    try:\n",
        "        importlib.import_module(pkg)\n",
        "        print(f\"{pkg} already installed.\")\n",
        "    except ImportError:\n",
        "        print(f\"Installing {pip_name}...\")\n",
        "        !pip install -q {pip_name}\n",
        "\n",
        "ensure(\"torchview\")\n",
        "ensure(\"torchviz\")\n",
        "ensure(\"torch_summary\", \"torch-summary\")\n",
        "ensure(\"seaborn\")\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from torchview import draw_graph\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', DEVICE)"
      ],
      "metadata": {
        "id": "RQzlOFfpDFmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.&nbsp;Hyperparameters\n",
        "Central config dictionary - change values here"
      ],
      "metadata": {
        "id": "8-eDK_jJLcMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'num_channels': 5,\n",
        "    'signal_length': 1000,\n",
        "    'input_window': 100,\n",
        "    'horizon': 10,\n",
        "    'hidden_size': 256,\n",
        "    'batch_size': 64,\n",
        "    'num_epochs': 100,\n",
        "    'learning_rate': 0.001,\n",
        "    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "config"
      ],
      "metadata": {
        "id": "adS0YbA_ND4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.&nbsp;Plotting functions\n",
        "Contains functions that produce a plot, used later in code for data visualization."
      ],
      "metadata": {
        "id": "T-6tgFbULffj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Shows all 5 channels & their states\n",
        "def plot_channels(channel_data, num_channels):\n",
        "    plt.figure(figsize=(14, 4))\n",
        "\n",
        "    offset = 1.5\n",
        "    yticks = []\n",
        "    yticklabels = []\n",
        "\n",
        "    for i in range(num_channels):\n",
        "        rev_i = num_channels - 1 - i\n",
        "        channel_offset = rev_i * offset\n",
        "\n",
        "        # Plot actual channel signal\n",
        "        plt.plot(channel_data[i] + channel_offset, label=f\"Channel {i+1}\")\n",
        "\n",
        "        # Add horizontal lines at 0 and 1 for this channel\n",
        "        plt.hlines(y=channel_offset + 0, xmin=0, xmax=channel_data.shape[1]-1, colors='gray', linestyles='dashed', linewidth=0.8)\n",
        "        plt.hlines(y=channel_offset + 1, xmin=0, xmax=channel_data.shape[1]-1, colors='gray', linestyles='dashed', linewidth=0.8)\n",
        "\n",
        "        # Set middle point for tick\n",
        "        mid = channel_offset + 0.5\n",
        "        yticks.append(mid)\n",
        "        yticklabels.append(f\"Ch {i+1}\")\n",
        "\n",
        "    plt.title(\"Simulated Channel Occupancy\")\n",
        "    plt.xlabel(\"Time step\")\n",
        "    plt.ylabel(\"Occupancy\")\n",
        "    plt.yticks(yticks, yticklabels)\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1.01, 1), borderaxespad=0)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 2. Shows heatmap sample from dataset, red = 0, green = 1\n",
        "def heatmap_dataset_sample_binary(X, y, sample_index=0, input_window=100, horizon=10):\n",
        "    marker_position = input_window + horizon  # 110\n",
        "    # Select the sample\n",
        "    X_sample = X[sample_index]\n",
        "    y_sample = y[sample_index]\n",
        "\n",
        "    # Combine input and horizon along time axis\n",
        "    combined = np.concatenate([X_sample, y_sample], axis=0).T  # shape -> (5, 110)\n",
        "    plt.figure(figsize=(13, 8))\n",
        "\n",
        "    ax = sns.heatmap(\n",
        "        combined,\n",
        "        cmap=[\"#d9534f\", \"#5cb85c\"],\n",
        "        cbar=False,\n",
        "        linewidths=0.5,\n",
        "        linecolor=\"black\",\n",
        "        square=True\n",
        "    )\n",
        "    ax.set_xlabel(\"Time step\", fontsize=16)\n",
        "    ax.set_ylabel(\"Channel\", fontsize=16)\n",
        "\n",
        "    # Channels\n",
        "    ax.set_yticks(np.arange(combined.shape[0]) + 0.5)\n",
        "    ax.set_yticklabels([str(i+1) for i in range(combined.shape[0])], fontsize=6)\n",
        "\n",
        "    # Vertical line separating input and horizon\n",
        "    ax.axvline(input_window, color=\"black\", linewidth=4)\n",
        "    ax.text(input_window + 0.5, -0.5, \"←Horizon→\", fontsize=10, color=\"black\")\n",
        "\n",
        "    # Reduce x-tick clutter\n",
        "    ax.set_xticks(np.arange(0, combined.shape[1], 10))\n",
        "    ax.set_xticklabels(np.arange(0, combined.shape[1], 10), rotation=90)\n",
        "\n",
        "    # Ensure 110 is included as a tick and appears below the heatmap\n",
        "    xticks = list(np.arange(0, combined.shape[1], 10))\n",
        "    if marker_position not in xticks:\n",
        "        xticks.append(marker_position)\n",
        "    ax.set_xticks(xticks)\n",
        "    ax.set_xticklabels([str(t) for t in xticks], rotation=90)\n",
        "\n",
        "    # Thick vertical line at 110\n",
        "    ax.axvline(marker_position, color='black', linewidth=3)\n",
        "    plt.title(f\"Dataset Sample #{sample_index}\", fontsize=16, pad=20)\n",
        "\n",
        "    # Define legend entries\n",
        "    legend_elements = [\n",
        "        Patch(facecolor='#d9534f', edgecolor='black', label='0'),\n",
        "        Patch(facecolor='#5cb85c', edgecolor='black', label='1')\n",
        "    ]\n",
        "    # Add legend to the axes\n",
        "    ax.legend(handles=legend_elements, title='Value', loc='upper right', bbox_to_anchor=(1.08, 1.2))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 3. Shows loss curve plotted over num. of epochs\n",
        "def plot_loss(loss_values, num_epochs):\n",
        "    min_loss_value = min(loss_values)\n",
        "    min_loss_epoch = loss_values.index(min_loss_value) + 1  # +1 because num_epochs start at 1\n",
        "    max_loss_value = max(loss_values)\n",
        "    last_loss_value = loss_values[num_epochs-1]\n",
        "    # Loss curve plot with best loss highlighted\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(range(1, num_epochs + 1), loss_values, marker='o', linestyle='-', label='Training Loss')\n",
        "\n",
        "    # Highlight the best loss\n",
        "    plt.plot(min_loss_epoch, min_loss_value, 'ro', label='Best Loss')\n",
        "    plt.annotate(f'Best: {min_loss_value:.4f}',\n",
        "                xy=(min_loss_epoch, min_loss_value),\n",
        "                xytext=(min_loss_epoch + 1, min_loss_value + 0.01),\n",
        "                arrowprops=dict(facecolor='red', arrowstyle='->'))\n",
        "\n",
        "    plt.title(\"Training Loss Over Epochs\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 4. Compares real channel data with predicted channel data (model doesn't predict first 100 time steps)\n",
        "def plot_compare_channels(X_raw, pred_full, warmup=config['input_window']):\n",
        "\n",
        "    pred_plot = pred_full.copy()\n",
        "    pred_plot[:, :warmup] = np.nan  # model doesn't predict first 100 time steps\n",
        "\n",
        "    num_channels = X_raw.shape[0]\n",
        "    fig, axes = plt.subplots(num_channels, 1, figsize=(35, 2*num_channels), sharex=False)\n",
        "\n",
        "    for i in range(num_channels):\n",
        "        ax = axes[i]\n",
        "\n",
        "        # Solid line for actual\n",
        "        ax.plot(X_raw[i], label=f\"Channel {i+1} Actual\", linewidth=2)\n",
        "\n",
        "        # Dashed line for predicted\n",
        "        ax.plot(pred_plot[i], '--', label=f\"Channel {i+1} Predicted\", linewidth=2)\n",
        "\n",
        "        ax.set_ylabel(\"Occupancy\")\n",
        "        ax.set_ylim(-0.1, 1.1)\n",
        "        ax.set_yticks([0, 1])\n",
        "        ax.set_title(f\"Channel {i+1}\")\n",
        "\n",
        "        # Horizontal 0/1 guide lines\n",
        "        ax.hlines([0, 1], xmin=0, xmax=X_raw.shape[1]-1, colors='gray', linestyles='dashed', linewidth=0.8)\n",
        "\n",
        "        # Vertical guidelines\n",
        "        ax.set_xticks(np.arange(0, X_raw.shape[1]+1, 50))\n",
        "        ax.grid(True, which='both', axis='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "        ax.legend(loc='upper left', bbox_to_anchor=(1.01, 1), borderaxespad=0)\n",
        "        ax.margins(x=0.01)\n",
        "\n",
        "    axes[-1].set_xlabel(\"Time step\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 5. Shows heatmap of first 100 predictions the model makes\n",
        "def heatmap_correctness_100(X_raw, pred_full, warmup=100, steps=config['input_window']):\n",
        "\n",
        "    X_raw_np = X_raw[:, warmup:warmup + steps]\n",
        "    pred_full_np = pred_full[:, warmup:warmup + steps]\n",
        "\n",
        "    pred_bin = (pred_full_np >= 0.5).astype(int)\n",
        "\n",
        "    correct_matrix = (pred_bin == X_raw_np).astype(int)\n",
        "\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    ax = sns.heatmap(\n",
        "        correct_matrix,\n",
        "        cmap=[\"#d9534f\", \"#5cb85c\"],\n",
        "        cbar=False,\n",
        "        linewidths=0.5,\n",
        "        linecolor=\"black\",\n",
        "        square=True\n",
        "    )\n",
        "\n",
        "    ax.set_xlabel(\"Time step\", fontsize=12)\n",
        "    ax.set_ylabel(\"Channel\", fontsize=12)\n",
        "\n",
        "    ax.set_yticks(np.arange(correct_matrix.shape[0]) + 0.5)\n",
        "    ax.set_yticklabels([str(i+1) for i in range(correct_matrix.shape[0])], rotation=90, fontsize=6)\n",
        "\n",
        "    x_ticks = list(np.arange(0, correct_matrix.shape[1], 20))\n",
        "    if correct_matrix.shape[1] not in x_ticks:\n",
        "        x_ticks.append(correct_matrix.shape[1])\n",
        "\n",
        "    ax.set_xticks(x_ticks)\n",
        "    ax.set_xticklabels([str(warmup + tick) for tick in x_ticks], rotation=90, fontsize=10)\n",
        "\n",
        "    plt.title(f\"Prediction Accuracy Heatmap ({warmup}–{warmup+steps} steps)\", fontsize=18, pad=20)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FDfMpyxPNLJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.&nbsp;Simulate channel data\n",
        "Simulates channels - Return array shape (num_channels, length) with 0/1 occupancy."
      ],
      "metadata": {
        "id": "gVkPvKYpLuhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_multiple_channels(num_channels=config['num_channels'], signal_length=config['signal_length'], avg_on_duration=20, avg_off_duration=30):\n",
        "    channels = []\n",
        "    for _ in range(num_channels):\n",
        "        channel = []\n",
        "        state = 0\n",
        "        while len(channel) < signal_length:\n",
        "            duration = np.random.exponential(scale=avg_on_duration if state == 1 else avg_off_duration)\n",
        "            duration = int(max(1, round(duration)))\n",
        "            channel.extend([state] * duration)\n",
        "            state = 1 - state\n",
        "        channels.append(channel[:signal_length])\n",
        "    return np.array(channels)\n",
        "\n",
        "channel_data = simulate_multiple_channels()\n",
        "plot_channels(channel_data, config['num_channels'])"
      ],
      "metadata": {
        "id": "sinP_OV_NNok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.&nbsp;Sequence creation & DataLoader\n",
        "Converts channel data into X y sliding windows & creates PyTorch DataLoader"
      ],
      "metadata": {
        "id": "7-D_fGKNL6Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "channel_data = channel_data.T # this transposes it to shape (time_steps, num_channels) for sequence slicing\n",
        "\n",
        "def create_sequence(channel_data, input_window=100, horizon=10):\n",
        "  X = [] # sequence of past channel states, contains a fixed length window of past observations\n",
        "  y = [] # sequence of steps after 10 steps (horizon, the num. of steps in the future we want to predict)\n",
        "  for i in range(len(channel_data) - input_window - horizon +1):\n",
        "    X.append(channel_data[i:i+input_window])\n",
        "    y.append(channel_data[i+input_window : i+input_window+horizon])\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequence(channel_data, input_window=100, horizon=10)\n",
        "print(f\"X.shape = {X.shape}, y.shape = {y.shape}\")\n",
        "# will give you 891 training samples from the dataset, 100 time steps, 5 values per channel\n",
        "\n",
        "# DataLoader part\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "\n",
        "batch_size = 64 # try out different values like 32 as well\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "OkuTMnZrObuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show heatmap sample from dataset\n",
        "heatmap_dataset_sample_binary(X, y, sample_index=0)\n"
      ],
      "metadata": {
        "id": "S8h8Z9Rej028"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.&nbsp;LSTM model definition\n",
        "Defines the LSTM model"
      ],
      "metadata": {
        "id": "NXTUz7rOMFLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_model(nn.Module):\n",
        "    def __init__(self, num_channels, horizon=10, hidden_size=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.horizon = horizon # number of future time steps to predict\n",
        "        self.num_channels = num_channels # number of channels/features in each input time step\n",
        "\n",
        "        self.lstm = nn.LSTM( # defines the LSTM layer:\n",
        "            input_size=num_channels, # input_size = num_channels: dimensionality of each input vector per time step (e.g., 5 channels)\n",
        "            hidden_size=hidden_size, # hidden_size = 256: dimensionality of the hidden state\n",
        "            batch_first=True # batch_first=True: input and output tensors have shape (batch, sequence_length, features)\n",
        "        )\n",
        "        self.fc = nn.Linear( # defines the fully connected (Linear) layer:\n",
        "            hidden_size, # maps the final LSTM hidden state of size (hidden_size) to the prediction of 'horizon' future steps for each channel\n",
        "            num_channels * horizon\n",
        "        )\n",
        "\n",
        "    def forward(self, x):  # x: (batch_size, 100, 5)\n",
        "        out, _ = self.lstm(x) # out: (batch_size, 100, 256)\n",
        "        last_out = out[:, -1, :] # last_out: (batch_size, 256)\n",
        "        preds = self.fc(last_out) # preds: (batch_size, 10*5) = (batch_size, 50)\n",
        "        preds = preds.view(-1, self.horizon, self.num_channels) # preds: (batch_size, 10, 5)\n",
        "        return torch.sigmoid(preds) # returns probabilities in range [0,1]\n"
      ],
      "metadata": {
        "id": "Cjd_Lq2bPEwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.&nbsp;Training loop\n",
        "Training loop for model"
      ],
      "metadata": {
        "id": "RHSHqKGMMUZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Training Parameters\n",
        "num_channels = X.shape[2]  # 5 channels\n",
        "horizon = y.shape[1]       # 10 time steps ahead\n",
        "loss_values = []\n",
        "#epochs = 100\n",
        "#lr = 0.001 # learning rate\n",
        "\n",
        "model = LSTM_model(num_channels=num_channels, horizon=horizon)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Variable to track best loss\n",
        "best_loss = float('inf')\n",
        "best_model_state = None  # to store the best model\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, config['num_epochs'] +1):\n",
        "  model.train()\n",
        "  epoch_loss = 0.0\n",
        "\n",
        "  for X_batch, y_batch in dataloader:\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_batch)\n",
        "    loss = criterion(outputs, y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "  avg_loss = epoch_loss / len(dataset)\n",
        "  loss_values.append(avg_loss)\n",
        "  print(f\"Epoch {epoch}/{config['num_epochs']} - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "  # Save best model\n",
        "  if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        best_model_state = model.state_dict()  # save model weights\n",
        "        #print(f\"  --> New best loss, saving model.\")\n",
        "\n",
        "# load the best model\n",
        "model.load_state_dict(best_model_state)\n",
        "print(f\"Training complete. Best loss: {best_loss:.4f}\")"
      ],
      "metadata": {
        "id": "dwFmQoKfPHRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(loss_values, config['num_epochs'])"
      ],
      "metadata": {
        "id": "Lvr5sfSHW5oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.&nbsp;Evaluate model on new dataset\n",
        "Evaluates the trained model on new dataset using the same `avg_on_duration` & `avg_off_duration` values used during training, then on multiple (num_tests) new datasets (generated using `simulate_multiple_channels`)"
      ],
      "metadata": {
        "id": "0AvRdlELMbBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def new_data(random_avg_on, random_avg_off): # set (0,0) to get random data values\n",
        "\n",
        "    if random_avg_on == 0 and random_avg_off == 0:\n",
        "        random_avg_on = random.randint(1, 100)\n",
        "        random_avg_off = random.randint(1, 100)\n",
        "\n",
        "    X_raw = simulate_multiple_channels(\n",
        "        num_channels=5,\n",
        "        signal_length=1000,\n",
        "        avg_on_duration=random_avg_on,\n",
        "        avg_off_duration=random_avg_off\n",
        "    )\n",
        "\n",
        "    X_raw_T = X_raw.T\n",
        "\n",
        "    # debug prints\n",
        "    #print(f\"Generated test data with values:\")\n",
        "    #print(f\"avg_on_duration: {random_avg_on}\")\n",
        "    #print(f\"avg_off_duration: {random_avg_off}\")\n",
        "\n",
        "    input_window = 100\n",
        "    horizon = 10\n",
        "    test_X, test_y = create_sequence(X_raw_T, input_window, horizon)\n",
        "\n",
        "    test_X_tensor = torch.tensor(test_X, dtype=torch.float32).to(device)\n",
        "    test_y_tensor = torch.tensor(test_y, dtype=torch.float32).to(device)\n",
        "\n",
        "    return test_X_tensor, test_y_tensor, X_raw_T, random_avg_on, random_avg_off\n",
        "\n",
        "\n",
        "def run_tests(num_tests):\n",
        "\n",
        "    rows = []\n",
        "    saved_results = []\n",
        "\n",
        "    model.load_state_dict(best_model_state)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"Loaded best model with loss: {best_loss:.4f}\")\n",
        "\n",
        "    for i in range(num_tests):\n",
        "        test_X_tensor, test_y_tensor, X_raw_T, avg_on, avg_off = new_data(0, 0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(test_X_tensor)\n",
        "\n",
        "        preds_binary = (preds >= 0.5).int()\n",
        "\n",
        "        correct = (preds_binary == test_y_tensor.int()).sum().item()\n",
        "        total = torch.numel(test_y_tensor)\n",
        "        acc_percent = (correct / total) * 100\n",
        "\n",
        "        # reconstruct full-length prediction here\n",
        "        pred_full, X_raw = reconstruct_full_prediction(preds_binary, X_raw_T, horizon=10)\n",
        "\n",
        "        # store for later use (plotting, analysis, etc.)\n",
        "        saved_results.append((pred_full, X_raw, preds_binary.cpu().numpy(), avg_on, avg_off, acc_percent))\n",
        "\n",
        "        rows.append(f\"{i+1:02d}\\t{avg_on}\\t{avg_off}\\t{acc_percent:.2f}\")\n",
        "\n",
        "    print(\"Test\\tavg_on_duration\\tavg_off_duration\\tAccuracy (%)\")\n",
        "    for r in rows:\n",
        "        print(r)\n",
        "\n",
        "    return rows, saved_results\n",
        "\n",
        "def reconstruct_full_prediction(preds_binary, X_raw_T, horizon=10):\n",
        "    \"\"\"\n",
        "    Reconstruct full-length prediction from overlapping windows.\n",
        "\n",
        "    preds_binary: torch.Tensor of shape (num_samples, horizon, num_channels)\n",
        "    X_raw_T: numpy array (time_steps, num_channels)\n",
        "    horizon: steps predicted per input sequence\n",
        "\n",
        "    Returns:\n",
        "        pred_full: numpy array (num_channels, signal_length)\n",
        "        X_raw: numpy array (num_channels, signal_length)\n",
        "    \"\"\"\n",
        "\n",
        "    preds_np = preds_binary.cpu().numpy()  # (num_samples, horizon, num_channels)\n",
        "    num_samples, horizon, num_channels = preds_np.shape\n",
        "\n",
        "    # Reconstruct the original signal orientation (num_channels, signal_length)\n",
        "    X_raw = X_raw_T.T  # (time_steps, channels) -> (channels, time_steps)\n",
        "    signal_length = X_raw.shape[1]\n",
        "\n",
        "    pred_full = np.zeros((num_channels, signal_length))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        start = i\n",
        "        end = min(i + horizon, signal_length)\n",
        "        pred_full[:, start:end] = preds_np[i, :end-start, :].T\n",
        "\n",
        "    return pred_full, X_raw\n",
        "\n",
        "# Calls\n",
        "table, results = run_tests(20)\n",
        "pred_full, X_raw, preds_binary, avg_on, avg_off, acc = results[0] # store the data from test #1"
      ],
      "metadata": {
        "id": "A5YPJSN1ZMOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on same avg_on & avg_off used during training\n",
        "def run_tests_training(num_tests):\n",
        "\n",
        "    rows = []\n",
        "    saved_results = []\n",
        "\n",
        "    model.load_state_dict(best_model_state)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"Loaded best model with loss: {best_loss:.4f}\")\n",
        "\n",
        "    for i in range(num_tests):\n",
        "        test_X_tensor, test_y_tensor, X_raw_T, avg_on, avg_off = new_data(20, 30)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(test_X_tensor)\n",
        "\n",
        "        preds_binary = (preds >= 0.5).int()\n",
        "\n",
        "        correct = (preds_binary == test_y_tensor.int()).sum().item()\n",
        "        total = torch.numel(test_y_tensor)\n",
        "        acc_percent = (correct / total) * 100\n",
        "\n",
        "        # reconstruct full-length prediction here\n",
        "        pred_full, X_raw = reconstruct_full_prediction(preds_binary, X_raw_T, horizon=10)\n",
        "\n",
        "        # store for later use (plotting, analysis, etc.)\n",
        "        saved_results.append((pred_full, X_raw, preds_binary.cpu().numpy(), avg_on, avg_off, acc_percent))\n",
        "\n",
        "        rows.append(f\"{i+1:02d}\\t{avg_on}\\t{avg_off}\\t{acc_percent:.2f}\")\n",
        "\n",
        "    print(\"Test\\tavg_on_duration\\tavg_off_duration\\tAccuracy (%)\")\n",
        "    for r in rows:\n",
        "        print(r)\n",
        "\n",
        "    return rows, saved_results\n",
        "\n",
        "table, results = run_tests_training(1)"
      ],
      "metadata": {
        "id": "kSyzVl-x1GWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_compare_channels(X_raw, pred_full) # shows data from test 01"
      ],
      "metadata": {
        "id": "mcyZbLHQ4Cp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap_correctness_100(X_raw, pred_full) # shows data from test 01"
      ],
      "metadata": {
        "id": "f3a8ako0AdL6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}